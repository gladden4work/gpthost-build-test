name: GPTHost Build Pipeline

on:
  workflow_dispatch:
    inputs:
      project_id:
        description: 'Project ID'
        required: true
        type: string
      source_files:
        description: 'Source files as JSON object'
        required: true
        type: string
      build_config:
        description: 'Build configuration (package.json content)'
        required: true
        type: string
      callback_url:
        description: 'Callback URL for build status'
        required: true
        type: string
      callback_token:
        description: 'Authentication token for callback'
        required: true
        type: string

env:
  NODE_VERSION: '20'
  PROJECT_ID: ${{ inputs.project_id }}
  CALLBACK_URL: ${{ inputs.callback_url }}
  CALLBACK_TOKEN: ${{ inputs.callback_token }}
  CACHE_VERSION: ${{ vars.CACHE_VERSION || '1' }}
  R2_PUBLIC_URL: ${{ vars.R2_PUBLIC_URL || '' }}

jobs:
  build:
    runs-on: ubuntu-latest
    timeout-minutes: 15
    
    steps:
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}

    - name: Create project directory
      run: |
        echo "Creating project directory structure..."
        mkdir -p projects/${{ inputs.project_id }}/src
        mkdir -p projects/${{ inputs.project_id }}/public
        mkdir -p artifacts/${{ inputs.project_id }}
        
        echo "Project directory created successfully"

    - name: Create source files from workflow input
      working-directory: projects/${{ inputs.project_id }}
      env:
        SOURCE_FILES: ${{ inputs.source_files }}
        BUILD_CONFIG: ${{ inputs.build_config }}
      run: |
        echo "Creating source files from workflow input..."
        # Use environment variable to avoid YAML parsing issues
        echo "$SOURCE_FILES" > source_files.json
        
        # Parse JSON and create files
        jq -r 'to_entries[] | [.key, .value] | @tsv' source_files.json | while IFS=$'\t' read -r filename content; do
          # Normalize filename
          filename=${filename#./}
          filename=${filename#/}

          # Basic safety: avoid path traversal
          if [[ "$filename" == *".."* ]]; then
            echo "Skipping unsafe path: $filename"
            continue
          fi

          # Decide target path
          if [[ "$filename" == public/* ]]; then
            target="$filename"
          elif [[ "$filename" == src/* ]]; then
            target="$filename"
          elif [[ "$filename" == "index.html" ]]; then
            target="public/index.html"
          else
            target="src/$filename"
          fi

          mkdir -p "$(dirname "$target")"
          printf '%s' "$content" > "$target"
          echo "Created: $target"
        done
        
        # Create package.json from build_config if not already created
        if [ ! -f "package.json" ]; then
          echo "Creating package.json from build_config..."
          # Use environment variable passed from step
          echo "$BUILD_CONFIG" > package.json
        fi
        
        rm source_files.json
        echo "Source files created successfully"
        ls -la
        if [ -d "src" ]; then
          echo "Source directory contents:"
          ls -la src/
        fi

    - name: Validate project structure
      working-directory: projects/${{ inputs.project_id }}
      run: |
        echo "Validating project structure..."
        
        if [ ! -f "package.json" ]; then
          echo "ERROR: package.json not found"
          exit 1
        fi
        
        if ! jq . package.json > /dev/null 2>&1; then
          echo "ERROR: Invalid JSON in package.json"
          cat package.json
          exit 1
        fi
        
        if [ ! -d "src" ] || [ -z "$(ls -A src)" ]; then
          echo "WARNING: No source files found in src directory"
          echo "This might be expected for some project types"
        fi
        
        echo "Project structure validation passed"
        echo "Package.json contents:"
        cat package.json | head -20

    - name: Install dependencies
      working-directory: projects/${{ inputs.project_id }}
      run: |
        echo "Installing dependencies..."
        npm install --no-audit --no-fund
        echo "Dependencies installed successfully"

    - name: Create build configuration
      working-directory: projects/${{ inputs.project_id }}
      run: |
        echo "Setting up build environment..."
        
        # Create basic index.html if missing (avoid heredoc to prevent YAML parsing issues)
        if [ ! -f "public/index.html" ] && [ ! -f "index.html" ]; then
          mkdir -p public
          printf '%s\n' \
            '<!DOCTYPE html>' \
            '<html lang="en">' \
            '<head>' \
            '  <meta charset="UTF-8">' \
            '  <meta name="viewport" content="width=device-width, initial-scale=1.0">' \
            '  <title>GPTHost Build</title>' \
            '</head>' \
            '<body>' \
            '  <div id="root"></div>' \
            '</body>' \
            '</html>' > public/index.html
        fi
        
        # Create vite config if missing (avoid heredoc)
        if [ ! -f "vite.config.js" ] && [ ! -f "vite.config.ts" ]; then
          printf '%s\n' \
            "import { defineConfig } from 'vite'" \
            "import react from '@vitejs/plugin-react'" \
            "" \
            "export default defineConfig({" \
            "  plugins: [react()]," \
            "  build: {" \
            "    outDir: 'dist'," \
            "    emptyOutDir: true" \
            "  }" \
            "})" > vite.config.js
        fi
        
        echo "Build configuration ready"

    - name: Build project
      working-directory: projects/${{ inputs.project_id }}
      run: |
        echo "Building project..."
        
        # Check if build script exists
        if npm run build --if-present; then
          echo "Build completed successfully"
        else
          echo "No build script found, checking for dist folder..."
          # For projects without build step, just verify files exist
          if [ -d "src" ]; then
            mkdir -p dist
            cp -r src/* dist/ 2>/dev/null || true
            cp public/index.html dist/ 2>/dev/null || true
            echo "Files copied to dist"
          fi
        fi
        
        # CRITICAL: Verify dist folder exists and has content
        echo "==============================================="
        echo "VERIFYING BUILD OUTPUT:"
        echo "==============================================="
        
        if [ -d "dist" ]; then
          echo "✓ dist folder exists"
          echo "Contents of dist folder:"
          ls -la dist/
          
          # Check for index.html
          if [ -f "dist/index.html" ]; then
            echo "✓ dist/index.html found"
            echo "First 10 lines of dist/index.html:"
            head -10 dist/index.html
          else
            echo "✗ WARNING: dist/index.html not found!"
          fi
          
          # Check for assets
          if [ -d "dist/assets" ]; then
            echo "✓ dist/assets folder found"
            echo "Assets:"
            ls -la dist/assets/
          else
            echo "ℹ No dist/assets folder (might be normal for some builds)"
          fi
        else
          echo "✗ ERROR: dist folder does not exist!"
          echo "Build may have failed. Current directory contents:"
          ls -la
          exit 1
        fi
        
        echo "==============================================="
        echo "Build verification completed"

    - name: Prepare artifacts
      run: |
        echo "==============================================="
        echo "PREPARING ARTIFACTS FOR UPLOAD:"
        echo "==============================================="
        
        # Check if dist folder exists
        if [ ! -d "projects/${{ inputs.project_id }}/dist" ]; then
          echo "✗ ERROR: dist folder not found at projects/${{ inputs.project_id }}/dist"
          echo "Current directory structure:"
          ls -la projects/${{ inputs.project_id }}/
          exit 1
        fi
        
        echo "✓ Found dist folder at projects/${{ inputs.project_id }}/dist"
        echo "Contents to be copied:"
        ls -la projects/${{ inputs.project_id }}/dist/
        
        # Copy dist contents to artifacts (without error suppression)
        echo "Copying dist contents to artifacts..."
        cp -rv projects/${{ inputs.project_id }}/dist/* artifacts/${{ inputs.project_id }}/
        
        # Verify the copy was successful
        echo "==============================================="
        echo "VERIFYING ARTIFACTS:"
        echo "==============================================="
        
        if [ -f "artifacts/${{ inputs.project_id }}/index.html" ]; then
          echo "✓ index.html copied successfully"
        else
          echo "✗ ERROR: index.html not found in artifacts!"
          echo "Artifacts directory contents:"
          ls -la artifacts/${{ inputs.project_id }}/
          exit 1
        fi
        
        # Create build manifest (use jq to avoid YAML heredoc issues)
        jq -n \
          --arg pid "${{ inputs.project_id }}" \
          --arg ts  "$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
          --arg run "${{ github.run_id }}" \
          '{project_id:$pid, build_timestamp:$ts, workflow_run:$run, status:"completed"}' \
          > artifacts/${{ inputs.project_id }}/build-manifest.json
        
        echo "==============================================="
        echo "FINAL ARTIFACTS TO BE UPLOADED:"
        echo "==============================================="
        echo "Files in artifacts/${{ inputs.project_id }}:"
        find artifacts/${{ inputs.project_id }} -type f | head -20
        echo ""
        echo "Total size of artifacts:"
        du -sh artifacts/${{ inputs.project_id }}/
        echo "==============================================="

    - name: Upload to Cloudflare R2
      if: success()
      working-directory: artifacts/${{ inputs.project_id }}
      env:
        CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
        R2_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
        R2_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
        R2_BUCKET_NAME: ${{ secrets.R2_BUCKET_NAME }}
        R2_PUBLIC_URL: ${{ env.R2_PUBLIC_URL }}
      run: |
        echo "==============================================="
        echo "UPLOADING TO CLOUDFLARE R2:"
        echo "==============================================="
        
        if [ -z "$CLOUDFLARE_ACCOUNT_ID" ] || [ -z "$R2_ACCESS_KEY_ID" ] || [ -z "$R2_SECRET_ACCESS_KEY" ] || [ -z "$R2_BUCKET_NAME" ]; then
          echo "Missing R2 secrets; skipping upload"; exit 1;
        fi
        
        # Verify we're uploading the right files
        echo "Current working directory: $(pwd)"
        echo "Files to be uploaded:"
        ls -la
        
        # Double-check we have index.html
        if [ ! -f "index.html" ]; then
          echo "✗ CRITICAL ERROR: index.html not found in upload directory!"
          echo "This means dist files were not copied correctly."
          exit 1
        fi
        
        echo "✓ index.html found, proceeding with upload..."
        
        if command -v aws >/dev/null 2>&1; then
          echo "Using preinstalled AWS CLI: $(aws --version)"
        else
          echo "Installing AWS CLI..."
          curl -fsSL https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip -o awscliv2.zip
          unzip -q awscliv2.zip
          sudo ./aws/install --update || sudo ./aws/install
          aws --version
        fi
        
        ENDPOINT="https://$CLOUDFLARE_ACCOUNT_ID.r2.cloudflarestorage.com"
        # Provide AWS CLI with credentials via env vars
        export AWS_ACCESS_KEY_ID="$R2_ACCESS_KEY_ID"
        export AWS_SECRET_ACCESS_KEY="$R2_SECRET_ACCESS_KEY"
        export AWS_DEFAULT_REGION="auto"
        
        BUILD_TIMESTAMP=$(date -u +%Y-%m-%dT%H-%M-%SZ)
        # Canonical R2 build artifacts path used by Workers: builds/{projectId}/{timestamp}
        BUILD_PATH="builds/${{ inputs.project_id }}/$BUILD_TIMESTAMP"
        echo "BUILD_PATH=$BUILD_PATH" >> $GITHUB_ENV
        echo "BUILD_TIMESTAMP=$BUILD_TIMESTAMP" >> $GITHUB_ENV
        echo "R2_ENDPOINT=$ENDPOINT" >> $GITHUB_ENV
        
        echo "Uploading files to s3://$R2_BUCKET_NAME/$BUILD_PATH" 
        
        # Upload files and log what's being uploaded
        find . -type f -print0 | while IFS= read -r -d '' f; do
          rel=${f#./}
          echo "Uploading: $rel"
          aws s3 cp "$f" "s3://$R2_BUCKET_NAME/$BUILD_PATH/$rel" \
            --endpoint-url "$ENDPOINT" --region auto --no-progress
        done
        
        if [ -n "$R2_PUBLIC_URL" ]; then
          PUB_BASE="${R2_PUBLIC_URL%/}/$BUILD_PATH"
          echo "PUBLIC_URL_BASE=$PUB_BASE" >> $GITHUB_ENV
          echo "Public URL Base: $PUB_BASE"
          echo "==============================================="
          echo "DEPLOYMENT URLS:"
          echo "==============================================="
          echo "Main URL: $PUB_BASE/index.html"
          echo "Root URL: $PUB_BASE/"
          echo "==============================================="
        fi

    - name: Send success callback
      if: success()
      run: |
        echo "Sending success callback..."
        
        # Build optional R2 payload
        R2_JSON=""; if [ -n "${PUBLIC_URL_BASE:-}" ]; then
          R2_JSON=", \"r2_storage\": { \"build_path\": \"${BUILD_PATH}\", \"bucket_name\": \"${R2_BUCKET_NAME}\", \"endpoint\": \"${R2_ENDPOINT}\", \"build_timestamp\": \"${BUILD_TIMESTAMP}\", \"public_url_base\": \"${PUBLIC_URL_BASE}\" }"
        elif [ -n "${BUILD_PATH:-}" ]; then
          R2_JSON=", \"r2_storage\": { \"build_path\": \"${BUILD_PATH}\", \"bucket_name\": \"${R2_BUCKET_NAME}\", \"endpoint\": \"${R2_ENDPOINT}\", \"build_timestamp\": \"${BUILD_TIMESTAMP}\" }"
        fi

        BODY="{\"status\": \"completed\", \"project_id\": \"${{ inputs.project_id }}\", \"build_timestamp\": \"$(date -u +%Y-%m-%dT%H:%M:%SZ)\", \"workflow_run_id\": \"${{ github.run_id }}\", \"github_run_id\": \"${{ github.run_id }}\", \"github_run_url\": \"${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}\"$R2_JSON }"

        HTTP_CODE=$(curl -s -o /tmp/callback_success.json -w "%{http_code}" -X POST "${{ inputs.callback_url }}" \
          -H "Content-Type: application/json" \
          -H "Authorization: Bearer ${{ inputs.callback_token }}" \
          -d "$BODY")

        echo "Callback HTTP_CODE: $HTTP_CODE"
        echo "Callback response (truncated):"
        tail -c 2000 /tmp/callback_success.json || true

        if [ "$HTTP_CODE" -lt 200 ] || [ "$HTTP_CODE" -ge 300 ]; then
          echo "Warning: Callback returned non-2xx status"
        fi
        
        echo "Build completed successfully!"

    - name: Send failure callback
      if: failure()
      run: |
        echo "Sending failure callback..."
        
        FAIL_BODY="{\"status\": \"failed\", \"project_id\": \"${{ inputs.project_id }}\", \"error_message\": \"Build failed - check workflow logs\", \"workflow_run_id\": \"${{ github.run_id }}\", \"github_run_id\": \"${{ github.run_id }}\", \"github_run_url\": \"${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}\" }"

        HTTP_CODE=$(curl -s -o /tmp/callback_failure.json -w "%{http_code}" -X POST "${{ inputs.callback_url }}" \
          -H "Content-Type: application/json" \
          -H "Authorization: Bearer ${{ inputs.callback_token }}" \
          -d "$FAIL_BODY")

        echo "Callback HTTP_CODE: $HTTP_CODE"
        echo "Callback response (truncated):"
        tail -c 2000 /tmp/callback_failure.json || true

        if [ "$HTTP_CODE" -lt 200 ] || [ "$HTTP_CODE" -ge 300 ]; then
          echo "Warning: Callback returned non-2xx status"
        fi
